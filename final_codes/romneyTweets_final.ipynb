{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import unicodedata as ud\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "import csv\n",
    "from itertools import izip\n",
    "import HTMLParser\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1: positive, -1: negative, 0: neutral, 2: mixed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:38:08-05:00</td>\n",
       "      <td>Insidious!&lt;e&gt;Mitt Romney&lt;/e&gt;'s Bain Helped Phi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:14:18-05:00</td>\n",
       "      <td>.@WardBrenda @shortwave8669 @allanbourdius you...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:27:16-05:00</td>\n",
       "      <td>&lt;e&gt;Mitt Romney&lt;/e&gt; still doesn't &lt;a&gt;believe&lt;/a...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:11:43-05:00</td>\n",
       "      <td>&lt;e&gt;Romney&lt;/e&gt;'s &lt;a&gt;tax plan&lt;/a&gt; deserves a 2nd...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date            time  \\\n",
       "0                  NaN             NaN   \n",
       "1  2012-10-16 00:00:00  09:38:08-05:00   \n",
       "2  2012-10-16 00:00:00  10:14:18-05:00   \n",
       "3  2012-10-16 00:00:00  09:27:16-05:00   \n",
       "4  2012-10-16 00:00:00  10:11:43-05:00   \n",
       "\n",
       "                                     Anootated tweet  Class  \n",
       "0    1: positive, -1: negative, 0: neutral, 2: mixed    NaN  \n",
       "1  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...   -1.0  \n",
       "2  .@WardBrenda @shortwave8669 @allanbourdius you...   -1.0  \n",
       "3  <e>Mitt Romney</e> still doesn't <a>believe</a...   -1.0  \n",
       "4  <e>Romney</e>'s <a>tax plan</a> deserves a 2nd...   -1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"C:\\\\Users\\\\Khushbu\\\\Desktop\\\\uic\\\\main\\\\Data Mining\\\\Project 2\\\\romneyTweets_Filtered.xlsx\");\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotatedTweet = data['Anootated tweet']\n",
    "actualClass = data['Class']\n",
    "lengthObama = len(data);\n",
    "\n",
    "annotatedTweet = annotatedTweet.drop(0)\n",
    "actualClass = actualClass.drop(0)\n",
    "\n",
    "\n",
    "annotatedTweetList = annotatedTweet.tolist();\n",
    "actualClassList = actualClass.tolist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_excel(\"C:\\\\Users\\\\swapnil sagar\\\\Documents\\\\UIC\\\\Data mining\\\\project 2\\\\testData.xlsx\");\n",
    "annotatedTweet = data['Anootated tweet']\n",
    "annotatedTweet = annotatedTweet.drop(0)\n",
    "annotatedTweetList = annotatedTweet.tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0;\n",
    "\n",
    "finalFilteredTweet = []\n",
    "\n",
    "def removeStopWords(tweet):\n",
    "    filtered_tweet = [];\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'));\n",
    "    word_tokens = word_tokenize(tweet);\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tweet.append(w);\n",
    "    \n",
    "    eachTweet = \" \".join(filtered_tweet)  \n",
    "    return eachTweet\n",
    "    \n",
    "    \n",
    "def preProcessTweets(annotatedTweet):\n",
    "        \n",
    "        #remove links\n",
    "        processedTweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', annotatedTweet);\n",
    "        #remove references with @<word>\n",
    "        processedTweet = re.sub(r'(\\s)@\\w+', r'', processedTweet)\n",
    "        processedTweet = re.sub(r'@\\w+', r'', processedTweet)\n",
    "        \n",
    "        # remove HTML tags from tweet\n",
    "        processedTweet = re.sub('<[^<]+?>', '', processedTweet)\n",
    "        \n",
    "        #remove exclamation marks - hashtags should be removed?\n",
    "        processedTweet = re.sub(r'[<>!#@$:,%\\?-]+', r' ', processedTweet)\n",
    "        processedTweet = re.sub(r'[.]+', r'', processedTweet)\n",
    "        \n",
    "       # processedTweet = re.sub(r'(\\s)#\\w+', r'', processedTweet)\n",
    "       # processedTweet = re.sub(r'#\\w+', r'', processedTweet)\n",
    "        \n",
    "        # remove extra white spaces\n",
    "        processedTweet = re.sub(r'\\s+', r' ', processedTweet)\n",
    "        \n",
    "        #remove \"\" \n",
    "        processedTweet = processedTweet.replace('\"', '');\n",
    "        \n",
    "        processedTweet = ''.join([i if ord(i) < 128 else ' ' for i in processedTweet])\n",
    "\n",
    "        #stemming\n",
    "        stemmer = porterStemmer()\n",
    "        stemmedTweet = [stemmer.stem(word) for word in processedTweet.split(\" \")]\n",
    "        stemmedTweet = \" \".join(stemmedTweet)\n",
    "        processedTweet = str(stemmedTweet);\n",
    "        \n",
    "        processedTweet = processedTweet.replace(\"'\", \"\");\n",
    "\n",
    "        #remove numbers from data\n",
    "        #join\n",
    "        #processedTweet = \" \".join(re.findall('[A-Z][^A-Z]*', processedTweet));\n",
    "\n",
    "        #processedTweet = removeStopWords(processedTweet); --- Remove stop words in the end\n",
    "        \n",
    "        return processedTweet;\n",
    "\n",
    "    \n",
    "for every_tweet in annotatedTweetList:\n",
    "    \n",
    "    count = count +1     \n",
    "    tweet = preProcessTweets(every_tweet).encode('ascii', 'ignore').strip();\n",
    "    #print type(tweet)\n",
    "\n",
    "    finalFilteredTweet.append(tweet);        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5648"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalFilteredTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insidi mitt romney bain help philip morri get US high schooler hook On cigarett via',\n",
       " 'you mean like romney cheat in primari',\n",
       " 'mitt romney still doesnt believ that we have a black presid',\n",
       " 'romney tax plan deserv a 2nd look becaus he ha a secret one that differ than the one he been lie about',\n",
       " 'hope romney debat prep w/ the same peopl as last time']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalFilteredTweet[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData, testTrainData , y_train, y_test = train_test_split(finalFilteredTweet, actualClassList, test_size = 0.15, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainData)\n",
    "len(testTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.00125,\n",
    "                             max_df = 0.70,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True,\n",
    "                            stop_words=u'english',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1,6),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_vectors = vectorizer.fit_transform(trainData);\n",
    "#test_vectors = vectorizer.transform(testTrainData);\n",
    "total_vectors = vectorizer.fit_transform(finalFilteredTweet);\n",
    "\n",
    "#knn = KNeighborsClassifier()\n",
    "classifier_sgd = linear_model.SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_sgd.fit(total_vectors, actualClassList)\n",
    "#knn.fit(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56603773584905659"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = classifier_sgd.predict(test_vectors)\n",
    "#predicted_labels = knn.predict(test_vectors)\n",
    "predicted_labelsList = predicted_labels.tolist();\n",
    "classifier_sgd.score(test_vectors, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.77      0.69       425\n",
      "          0       0.42      0.33      0.37       252\n",
      "          1       0.57      0.39      0.46       171\n",
      "\n",
      "avg / total       0.55      0.57      0.55       848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_classifiers = ['-1', '0', '1']\n",
    "print(classification_report(y_test, predicted_labelsList, target_names=target_classifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predicted list for test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, Class]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=['id','Class'])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for num in predicted_labelsList:\n",
    "    submission.loc[i+1] = [i+1,predicted_labelsList[i]]\n",
    "\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Class\n",
       "1  1.0   -1.0\n",
       "2  2.0   -1.0\n",
       "3  3.0   -1.0\n",
       "4  4.0    0.0\n",
       "5  5.0   -1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt(r'C:\\Users\\swapnil sagar\\Documents\\UIC\\Data mining\\project 2\\output_Romney.txt', submission.values, fmt='%d')\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56838101  0.50632915  0.52121745  0.53164086  0.53960149  0.56352106\n",
      "  0.55873243  0.49270258  0.54302728  0.58808493]\n"
     ]
    }
   ],
   "source": [
    "cvScores = cross_val_score(classifier_sgd, total_vectors, actualClassList, cv=10,scoring='f1_weighted')\n",
    "print (cvScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean: ', 0.54132382496854459)\n",
      "('Minimum: ', 0.49270258339693024)\n",
      "('Maximum: ', 0.58808492664499701)\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean: \", cvScores.mean())\n",
    "print (\"Minimum: \", cvScores.min())\n",
    "print (\"Maximum: \", cvScores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ..., -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "cvPredict = cross_val_predict(classifier_sgd, total_vectors, actualClassList, cv=10)\n",
    "print (cvPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.62      0.76      0.69      2893\n",
      "        0.0       0.41      0.32      0.36      1680\n",
      "        1.0       0.51      0.40      0.45      1075\n",
      "\n",
      "avg / total       0.54      0.56      0.54      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(actualClassList,cvPredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADA BOOST WITH SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdt = AdaBoostClassifier(classifier_sgd,\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ..., -1.  0. -1.]\n"
     ]
    }
   ],
   "source": [
    "cvPredict = cross_val_predict(bdt, total_vectors, actualClassList, cv=10)\n",
    "print (cvPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.63      0.63      0.63      2893\n",
      "        0.0       0.37      0.37      0.37      1680\n",
      "        1.0       0.41      0.40      0.40      1075\n",
      "\n",
      "avg / total       0.51      0.51      0.51      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(actualClassList,cvPredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FOR TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Anootated tweet\n",
      "1  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...\n",
      "2  Senior <e>Romney</e> Advisor Claims <e>Obama</...\n",
      "3  .@WardBrenda @shortwave8669 @allanbourdius you...\n",
      "4  <e>Mitt Romney</e> still doesn't <a>believe</a...\n"
     ]
    }
   ],
   "source": [
    "dataNew = pd.read_excel(\"C:\\\\Users\\\\Khushbu\\\\Desktop\\\\uic\\\\main\\\\Data Mining\\\\Project 2\\\\sample-testdata.xlsx\",sheetname = \"Romney\");\n",
    "print dataNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u\"Insidious!<e>Mitt Romney</e>'s Bain Helped Philip Morris Get U.S. High Schoolers <a>Hooked On Cigarettes</a> http://t.co/nMKuFcUq via @HuffPostPol\", u'Senior <e>Romney</e> Advisor Claims <e>Obama</e> Administration Is Deliberately <a>Misleading Public On Libya</a>: http://t.co/cpJjGsCF tp #US', u'.@WardBrenda @shortwave8669 @allanbourdius you mean like <e>romney </e><a>cheated in primary</a>?', u\"<e>Mitt Romney</e> still doesn't <a>believe</a> that we <a>have a black president</a>.\"]\n"
     ]
    }
   ],
   "source": [
    "annotatedTweetTest = dataNew['Anootated tweet']\n",
    "#annotatedTweetTest = annotatedTweet.drop(0)\n",
    "annotatedTweetListTest = annotatedTweetTest.tolist();\n",
    "print annotatedTweetListTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0;\n",
    "\n",
    "finalFilteredTweet = []\n",
    "\n",
    "def removeStopWords(tweet):\n",
    "    filtered_tweet = [];\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'));\n",
    "    word_tokens = word_tokenize(tweet);\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tweet.append(w);\n",
    "    \n",
    "    eachTweet = \" \".join(filtered_tweet)  \n",
    "    return eachTweet\n",
    "    \n",
    "    \n",
    "def preProcessTweets(annotatedTweet):\n",
    "        \n",
    "        #remove links\n",
    "        processedTweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', annotatedTweet);\n",
    "        #remove references with @<word>\n",
    "        processedTweet = re.sub(r'(\\s)@\\w+', r'', processedTweet)\n",
    "        processedTweet = re.sub(r'@\\w+', r'', processedTweet)\n",
    "        \n",
    "        # remove HTML tags from tweet\n",
    "        processedTweet = re.sub('<[^<]+?>', '', processedTweet)\n",
    "        \n",
    "        #remove exclamation marks - hashtags should be removed?\n",
    "        processedTweet = re.sub(r'[<>!#@$:,%\\?-]+', r' ', processedTweet)\n",
    "        processedTweet = re.sub(r'[.]+', r'', processedTweet)\n",
    "        \n",
    "       # processedTweet = re.sub(r'(\\s)#\\w+', r'', processedTweet)\n",
    "       # processedTweet = re.sub(r'#\\w+', r'', processedTweet)\n",
    "        \n",
    "        # remove extra white spaces\n",
    "        processedTweet = re.sub(r'\\s+', r' ', processedTweet)\n",
    "        \n",
    "        #remove \"\" \n",
    "        processedTweet = processedTweet.replace('\"', '');\n",
    "        \n",
    "        processedTweet = ''.join([i if ord(i) < 128 else ' ' for i in processedTweet])\n",
    "\n",
    "        #stemming\n",
    "        stemmer = porterStemmer()\n",
    "        stemmedTweet = [stemmer.stem(word) for word in processedTweet.split(\" \")]\n",
    "        stemmedTweet = \" \".join(stemmedTweet)\n",
    "        processedTweet = str(stemmedTweet);\n",
    "        \n",
    "        processedTweet = processedTweet.replace(\"'\", \"\");\n",
    "\n",
    "        #remove numbers from data\n",
    "        #join\n",
    "        #processedTweet = \" \".join(re.findall('[A-Z][^A-Z]*', processedTweet));\n",
    "\n",
    "        #processedTweet = removeStopWords(processedTweet); --- Remove stop words in the end\n",
    "        \n",
    "        return processedTweet;\n",
    "\n",
    "    \n",
    "for every_tweet in annotatedTweetListTest:\n",
    "    \n",
    "    count = count +1     \n",
    "    tweet = preProcessTweets(every_tweet).encode('ascii', 'ignore').strip();\n",
    "    #print type(tweet)\n",
    "\n",
    "    finalFilteredTweet.append(tweet);        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY VECTORIZER ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x1600 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors_new = vectorizer.transform(finalFilteredTweet);\n",
    "test_vectors_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0, -1.0, -1.0, -1.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = classifier_sgd.predict(test_vectors_new)\n",
    "#predicted_labels = knn.predict(test_vectors)\n",
    "predicted_labelsList = predicted_labels.tolist();\n",
    "predicted_labelsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DATA ON THE OUTPUT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>extra_column_for_tab</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, extra_column_for_tab, Class]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=['id','extra_column_for_tab','Class'])\n",
    "#submission.loc[0] = [1, 2, 3]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for num in predicted_labelsList:\n",
    "    submission.loc[i+1] = [i+1,';;',predicted_labelsList[i]]\n",
    "\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.head(5)\n",
    "np.savetxt(r'C:\\Users\\Khushbu\\Desktop\\uic\\main\\Data Mining\\Project 2\\output_romney.txt', submission.values, fmt='%d%s%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import unicodedata as ud\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "import csv\n",
    "import HTMLParser\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from numpy import random\n",
    "#from stemming.porter2 import stem\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer\n",
    "from itertools import izip\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanTweet(originalTweet):\n",
    "    htmlParser = HTMLParser.HTMLParser()\n",
    "\n",
    "    tweet = originalTweet\n",
    "    #tweet = htmlParser.unescape(originalTweet);\n",
    "    #tweet = tweet.decode('windows-1252').encode('ascii', 'ignore')\n",
    "    #tweet = tweet.decode('windows-1252')\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #tweet = re.sub(r'[^\\x00-\\xFF]+', r'', tweet)\n",
    "    #tweet = re.sub(r'[^\\x00-\\x7F]+', r'', tweet)\n",
    "    #tweet = tweet.decode('utf-8').strip()\n",
    "    #tweet = tweet.decode('unicode_escape').encode('ascii','ignore')\n",
    "    #tweet = tweet.encode('ascii','ignore')\n",
    "    tweet = ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "    \n",
    "    # remove URLs in tweet\n",
    "    tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "\n",
    "    # remove strings starting with @ in tweet\n",
    "    tweet = re.sub(r'(\\s)@\\w+', r'', tweet)\n",
    "    tweet = re.sub(r'@\\w+', r'', tweet)\n",
    "    \n",
    "    # remove HTML tags from tweet\n",
    "    tweet = re.sub('<[^<]+?>', '', tweet)\n",
    "\n",
    "    # separates words joined with capital words.\n",
    "    # E.g. DisplayIsAweson to Display Is Awesom\n",
    "    #tweet = \" \".join(re.findall('[A-Z][^A-Z]*', tweet));\n",
    "\n",
    "    # remove exclamations\n",
    "    tweet = re.sub(r'[<>!#@$:.,%\\?-]+', r'', tweet)\n",
    "\n",
    "    # remove extra white spaces\n",
    "    tweet = re.sub(r'\\s+', r' ', tweet)\n",
    "    \n",
    "    # stemming\n",
    "    stemmer = porterStemmer()\n",
    "    stemmedTweet = [stemmer.stem(word) for word in tweet.split(\" \")]\n",
    "    stemmedTweet = \" \".join(stemmedTweet)\n",
    "    \n",
    "    tweet = str(stemmedTweet)\n",
    "    tweet = tweet.replace(\"'\", \"\")\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"A:\\\\new_Sync\\\\Box Sync\\\\academics\\\\sem3\\\\583\\\\project\\\\TwitterAnalysis\\\\data\\\\trainRomney_3_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"A:\\\\new_Sync\\\\Box Sync\\\\academics\\\\sem3\\\\583\\\\project\\\\TwitterAnalysis\\\\data\\\\trainObama_3_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawTweetsSeries = data['Anootated tweet'];\n",
    "tweetLabels = data['Class'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawTweetsList = rawTweetsSeries.tolist()\n",
    "tweetLabelList = tweetLabels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawTweetsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomTweets = random.choice(rawTweetsList, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#randomTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean all the tweets\n",
    "i = 0;\n",
    "cleanedTweetsList = []\n",
    "for tweet in rawTweetsList:\n",
    "    #tweet.encode('utf-8').strip()\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #print (i ,),\n",
    "    cleanedTweet = cleanTweet(tweet).encode('ascii', 'ignore').strip();\n",
    "    cleanedTweetsList.append(cleanedTweet);\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (i)\n",
    "#print (len(cleanedTweetsList))\n",
    "#print (random.choice(cleanedTweetsList, 5))\n",
    "#print (type(cleanedTweetsList[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('cleanedRomney.csv', 'wb') as f:\n",
    "#    writer = csv.writer(f)\n",
    "#    writer.writerows(izip(cleanedTweetsList, tweetLabelList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#documents = [[stem(word) for word in sentence.split(\" \")] for sentence in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTweets, testTweets, trainTweetLabels, testTweetLabels = train_test_split(cleanedTweetsList, tweetLabelList, \n",
    "                                                                              test_size=0.15, random_state = 40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=0.00125,\n",
    "                             max_df = 0.70,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True,\n",
    "                            stop_words=u'english',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1,6),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(trainTweets);\n",
    "test_vectors = vectorizer.transform(testTweets);\n",
    "total_vectors = vectorizer.fit_transform(cleanedTweetsList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=18, criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=18, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_vectors, trainTweetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = classifier.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictedLabelList = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classActual = np.array(testTweetLabels)\n",
    "\n",
    "classPredicted = np.array(predictedLabelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['-1', '0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5795053,  0.503125 ,  0.6846473]),\n",
       " array([ 0.5754386 ,  0.56293706,  0.6043956 ]),\n",
       " array([ 0.57746479,  0.53135314,  0.64202335]),\n",
       " array([285, 286, 273], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prfs(classActual, classPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844\n",
      "844\n"
     ]
    }
   ],
   "source": [
    "print (len(predictedLabelList))\n",
    "print (len(testTweetLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = 0;\n",
    "for i in range(len(predictedLabelList)):\n",
    "    if(predictedLabelList[i] == testTweetLabels[i]):\n",
    "        correct += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1L"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedLabelList[170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0L: 320, -1L: 283, 1L: 241})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(predictedLabelList)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 286, -1: 285, 1: 273})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(testTweetLabels)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58056872037914697"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_vectors, testTweetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.58      0.58      0.58       285\n",
      "          0       0.50      0.56      0.53       286\n",
      "          1       0.68      0.60      0.64       273\n",
      "\n",
      "avg / total       0.59      0.58      0.58       844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testTweetLabels, predictedLabelList, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvScores = cross_val_score(classifier, total_vectors, tweetLabelList, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean: ', 0.54888666488711491)\n",
      "('Minimum: ', 0.49555950266429838)\n",
      "('Maximum: ', 0.58969804618117228)\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean: \", cvScores.mean())\n",
    "print (\"Minimum: \", cvScores.min())\n",
    "print (\"Maximum: \", cvScores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stemming tweets\n",
    "stemmer = porterStemmer()\n",
    "stemmedTweetsList = [[stemmer.stem(word) for word in sentence.split(\" \")] for sentence in cleanedTweetsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(stemmedTweetsList[0]))\n",
    "mystr = str(stemmedTweetsList[0])\n",
    "print (type(mystr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stemmedTweetsList = [\" \".join(sentence) for sentence in stemmedTweetsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stemmedTweetsList"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

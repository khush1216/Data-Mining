{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import unicodedata as ud\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "import csv\n",
    "from itertools import izip\n",
    "import HTMLParser\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanTweet(originalTweet):\n",
    "    htmlParser = HTMLParser.HTMLParser()\n",
    "\n",
    "    tweet = originalTweet\n",
    "    #tweet = htmlParser.unescape(originalTweet);\n",
    "    #tweet = tweet.decode('windows-1252').encode('ascii', 'ignore')\n",
    "    #tweet = tweet.decode('windows-1252')\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #tweet = re.sub(r'[^\\x00-\\xFF]+', r'', tweet)\n",
    "    #tweet = re.sub(r'[^\\x00-\\x7F]+', r'', tweet)\n",
    "    #tweet = tweet.decode('utf-8').strip()\n",
    "    #tweet = tweet.decode('unicode_escape').encode('ascii','ignore')\n",
    "    #tweet = tweet.encode('ascii','ignore')\n",
    "    tweet = ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "    \n",
    "    # remove URLs in tweet\n",
    "    tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "\n",
    "    # remove HTML tags from tweet\n",
    "    tweet = re.sub('<[^<]+?>', '', tweet)\n",
    "\n",
    "    # remove strings starting with @ in tweet\n",
    "    tweet = re.sub(r'(\\s)@\\w+', r'', tweet)\n",
    "\n",
    "    # remove exclamations\n",
    "    tweet = re.sub(r'!', r' ', tweet)\n",
    "\n",
    "    # separates words joined with capital words.\n",
    "    # E.g. DisplayIsAweson to Display Is Awesom\n",
    "    #tweet = \" \".join(re.findall('[A-Z][^A-Z]*', tweet));\n",
    "\n",
    "    # remove extra white spaces\n",
    "    tweet = re.sub(r'\\s+', r' ', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"A:\\\\new_Sync\\\\Box Sync\\\\academics\\\\sem3\\\\583\\\\project\\\\TwitterAnalysis\\\\data\\\\trainRomney_3_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\shekh\\\\Desktop\\\\twitteranalysis\\\\src\\\\trainObama_3_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawTweetsSeries = data['Anootated tweet'];\n",
    "tweetLabels = data['Class'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawTweetsList = rawTweetsSeries.tolist()\n",
    "tweetLabelList = tweetLabels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawTweetsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean all the tweets\n",
    "i = 0;\n",
    "cleanedTweetsList = []\n",
    "for tweet in rawTweetsList:\n",
    "    #tweet.encode('utf-8').strip()\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #print (i ,),\n",
    "    cleanedTweet = cleanTweet(tweet).encode('ascii', 'ignore').strip();\n",
    "    cleanedTweetsList.append(cleanedTweet);\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@realDonaldTrump I agree we cant afford 4 more years of Obama'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedTweetsList[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5624\n",
      "5624\n"
     ]
    }
   ],
   "source": [
    "print (i)\n",
    "print (len(cleanedTweetsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('cleanedRomney.csv', 'wb') as f:\n",
    "#    writer = csv.writer(f)\n",
    "#    writer.writerows(izip(cleanedTweetsList, tweetLabelList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainTweets, testTweets, trainTweetLabels, testTweetLabels = train_test_split(cleanedTweetsList, tweetLabelList, \n",
    "                                                                              test_size=0.25, random_state = 40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4218"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainTweetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df = 0.75,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(trainTweets);\n",
    "test_vectors = vectorizer.transform(testTweets);\n",
    "total_vectors = vectorizer.fit_transform(cleanedTweetsList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier_rbf = svm.SVC()      default kernel RBF. Very poor results, classify all tweets as -1\n",
    "#classifier_rbf = svm.SVC(kernel='linear')     decent results, ~50-60 accuracy\n",
    "#classifier_rbf = svm.LinearSVC()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_vectors, trainTweetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_rbf = knn.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictedLabelList = prediction_rbf.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classActual = np.array(testTweetLabels)\n",
    "\n",
    "classPredicted = np.array(predictedLabelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classActual\n",
    "len(classActual)\n",
    "\n",
    "classPredicted\n",
    "len(classPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['-1', '0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.53398058,  0.39543058,  0.36239782]),\n",
       " array([ 0.11578947,  0.45638945,  0.60730594]),\n",
       " array([ 0.19031142,  0.42372881,  0.45392491]),\n",
       " array([475, 493, 438]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prfs(classActual, classPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406\n",
      "1406\n"
     ]
    }
   ],
   "source": [
    "print (len(predictedLabelList))\n",
    "print (len(testTweetLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0;\n",
    "for i in range(len(predictedLabelList)):\n",
    "    if(predictedLabelList[i] == testTweetLabels[i]):\n",
    "        correct += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546\n"
     ]
    }
   ],
   "source": [
    "print (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1L"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedLabelList[470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1L: 734, 0L: 569, -1L: 103})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(predictedLabelList)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 493, -1: 475, 1: 438})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(testTweetLabels)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38833570412517782"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_vectors, testTweetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.12      0.19       475\n",
      "          0       0.40      0.46      0.42       493\n",
      "          1       0.36      0.61      0.45       438\n",
      "\n",
      "avg / total       0.43      0.39      0.35      1406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testTweetLabels, predictedLabelList, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvScores = cross_val_score(knn, total_vectors, tweetLabelList, cv=10,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validations scores:  [ 0.37047013  0.33532492  0.41618448  0.40096183  0.36519739  0.38130038\n",
      "  0.43932854  0.35902998  0.3630798   0.3505088 ]\n"
     ]
    }
   ],
   "source": [
    "print (\"Cross validations scores: \"),\n",
    "print (cvScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean: ', 0.37813862405912596)\n",
      "('Minimum: ', 0.33532491767764361)\n",
      "('Maximum: ', 0.43932853802758487)\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean: \", cvScores.mean())\n",
    "print (\"Minimum: \", cvScores.min())\n",
    "print (\"Maximum: \", cvScores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
